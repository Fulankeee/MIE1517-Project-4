{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bphECiUa9zw"
      },
      "source": [
        "# Assignment 4: Movie Review Analysis [50 Pt]\n",
        "\n",
        "In this assignment, we will build a recurrent neural network to work with sequential text data, specificially, movie review data to identify the reviewer sentiment. In the process of completing this assignment, you will:\n",
        "    \n",
        "1. Clean and process text data for machine learning.\n",
        "2. Perform tokenization of text data.\n",
        "3. Understand and implement a word-level recurrent neural network.\n",
        "4. Implement batching of text data using a DataLoader before training a recurrent neural network.\n",
        "5. Understand how to apply pretrained models for transfer learning in natural language processing projects.\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit an HTML file containing all your code, outputs, and write-up\n",
        "from parts A and B. You can produce a HTML file directly from Google Colab. The Colab instructions are provided at the end of this document.\n",
        "\n",
        "Include a link to your colab file in your submission.\n",
        "\n",
        "Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission.\n",
        "\n",
        "This year we will be using an autograding script to check your model performance on a hidden test set. To do this, we need you to provide your model definition and your model weights along with your assignment submission.\n",
        "\n",
        "Instructions on the additional files you need to submit are provided below. Please make sure to test your submitted files before submitting them, failure in loading these files may result in a grade of 0 in the results section of the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìë **Autograding**\n",
        "\n",
        "This assignment uses an autograding script to **evaluate your model performance on a hidden test set**. You must provide your model definition and model weights along with your assignment submission to ensure compatibility with the autograding system.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÅ **Required Files for Submission**\n",
        "\n",
        "You need to submit the following **four files** in addition to the **HTML file** as previously instructed. Make sure to replace `your_name_connected_by_underscore` and `your_student_id` with your actual name and student ID, respectively:\n",
        "\n",
        "1. **RNN Model Definition:** `A4-RNN-your_name_connected_by_underscore-your_student_id.py`\n",
        "2. **RNN Model Weights:** `A4-RNN-your_name_connected_by_underscore-your_student_id.pth`\n",
        "3. **BERT Model Definition:** `A4-BERT-your_name_connected_by_underscore-your_student_id.py`\n",
        "4. **BERT Model Weights:** `A4-BERT-your_name_connected_by_underscore-your_student_id.pth`\n",
        "\n",
        "---\n",
        "\n",
        "## üßë‚Äçüíª **Model Definition Files (`.py`)**\n",
        "\n",
        "### üìù **Steps to Complete:**\n",
        "\n",
        "1. **Copy Model Definition Code:** Copy the complete model definition code from your `A4.ipynb` notebook into the provided template files (`.py`).\n",
        "2. **Complete the TODOs:** Make sure all TODOs in the files are properly completed:\n",
        "   - Define your model class (`SentimentRNN` or `SentimentClassifier`).\n",
        "   - Implement the `prepare_model()` function with the exact hyperparameters used during training.\n",
        "   - Ensure preprocessing steps match those in your notebook.\n",
        "   - Set the `EMBEDDINGS_TYPE` parameter appropriately (`'pooled'` or `'last_hidden_state'` for BERT).\n",
        "3. **Command-Line Usability:** Ensure the script accepts a file path as an argument and runs from the command line as described in the file headers.\n",
        "\n",
        "---\n",
        "\n",
        "### üíª **Example Command-Line Usage**\n",
        "\n",
        "```bash\n",
        "python A4-RNN-your_name_connected_by_underscore-your_student_id.py /path/to/test_dataset.csv\n",
        "```\n",
        "---\n",
        "\n",
        "\n",
        "## üíæ **Model Weights Files (`.pth`)**\n",
        "\n",
        "1. **Save Model Weights:** During training, save your model's best-performing weights using the `torch.save()` method.\n",
        "2. **Naming Convention:** Ensure the `.pth` file names match the `.py` file names exactly, except for the file extension.\n",
        "3. **Example Code for Saving Weights:**\n",
        "\n",
        "```python\n",
        "torch.save(model.state_dict(), 'A4-RNN-your_name_connected_by_underscore-your_student_id.pth')\n",
        "```\n",
        "---\n",
        "\n",
        "## ‚úÖ **Testing Your Submission: Autograder Compatibility**\n",
        "\n",
        "You will be provided with an **\"Example Test IMDB Dataset.csv\"** that you can use to test your autograding file compatibility. Please follow the example command line usage to provide the test data to test the script for each of the two `.py` scripts you are submitting.\n",
        "\n",
        "### üß™ **How to Test:**\n",
        "\n",
        "1. **Run the Test Notebook:** Open and run the `test_your_submitted_files.ipynb` notebook.\n",
        "2. **Verify Output:** Ensure the notebook can:\n",
        "   - Load your `.py` model definition files.\n",
        "   - Load your `.pth` model weights files.\n",
        "   - Run predictions correctly using the provided **Example Test IMDB Dataset.csv**.\n",
        "3. **Debug as Needed:** If any step fails, debug the issue and retest before submission (You can ask for help on Piazza!).\n",
        "\n",
        "---\n",
        "\n",
        "### üö¶ **Autograder Sentinel Lines**\n",
        "\n",
        "Make sure your scripts output predictions between the sentinel lines **exactly** as shown below:\n",
        "\n",
        "```text\n",
        "===start_output===\n",
        "0\n",
        "1\n",
        "0\n",
        "1\n",
        "...\n",
        "===end_output===\n",
        "```"
      ],
      "metadata": {
        "id": "5s7OtrB7hhhE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWiUqJJTa9z6"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your Colab file here. If you would like the TA to look at your Colab file in case your solutions are cut off, **please make sure that your Colab file is publicly accessible at the time of submission.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "# http://https://colab.research.google.com/github/Fulankeee/MIE1517-Project-4/blob/main/A4.ipynb#scrollTo=rk7aDAaR2_wz"
      ],
      "metadata": {
        "id": "rk7aDAaR2_wz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFMdtipUPNdu"
      },
      "source": [
        "# PART A - Sentiment Analysis\n",
        "\n",
        "In this part we will construct a world-level LSTM model for identifying positive and negative reviews. This will be done in a similar way to what was shared in the preparation code for Assignment 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgfNOUaPa9z8",
        "outputId": "3fb7011f-0ab3-42a3-8ec1-673551c3dd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load standard modules/libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load special modules/libraries\n",
        "import os\n",
        "import warnings\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "from tqdm  import tqdm\n",
        "\n",
        "# load pytorch modules/libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset,DataLoader\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jLI9LBa90C"
      },
      "source": [
        "## Part 1. Data Cleaning [5 pt]\n",
        "\n",
        "We will be using the \"IMDB Movie Review Dataset\" provided on the course website. Download \"IMDB Dataset.csv\" into your Colab workspace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSuF7C_Ga90E"
      },
      "source": [
        "### Part (i) [1pt EXPLORATORY]\n",
        "\n",
        "Open up the file in Python, and examine some examples of positive and negative reviews. Comment on the quality of the data and any challenges you foresee in working with these data. Pick one example of a positive review and one of a negative review to support your comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IfXHeTa90F"
      },
      "source": [
        "# download IMDB review data\n",
        "\n",
        "# load dataset\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "\n",
        "# process into data and labels\n",
        "X = df['review'].values\n",
        "y = df['sentiment'].values\n"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8DEb5pmh07Ka",
        "outputId": "9aebbe12-825a-4207-c2fa-bb9e36bca8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  I really liked this Summerslam due to the look...  positive\n",
              "1  Not many television shows appeal to quite as m...  positive\n",
              "2  The film quickly gets to a major chase scene w...  negative\n",
              "3  Jane Austen would definitely approve of this o...  positive\n",
              "4  Expectations were somewhat high for me when I ...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b575dd7-1d2f-46ca-b556-28f38c48e6c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I really liked this Summerslam due to the look...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not many television shows appeal to quite as m...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The film quickly gets to a major chase scene w...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jane Austen would definitely approve of this o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Expectations were somewhat high for me when I ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b575dd7-1d2f-46ca-b556-28f38c48e6c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b575dd7-1d2f-46ca-b556-28f38c48e6c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b575dd7-1d2f-46ca-b556-28f38c48e6c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2db1515-8e88-40bb-952c-c3e22fb883cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2db1515-8e88-40bb-952c-c3e22fb883cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2db1515-8e88-40bb-952c-c3e22fb883cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39731,\n        \"samples\": [\n          \"I was on my way out one morning when I was checking something on the T.V. and came across this film. I don't ever remember seeing this or hearing of it. What a fun and interesting one to watch. Well, my meeting was pushed back, because I couldn't get out of this film. It had some real interesting things in it that marked it's time in history, and some fun things that they don't have people do in today's film because it's not pretty. Well, there was a lot of realism in it. The acting was good for a 1954 film. Subtle and genuine actions on the part of the characters that had me watching what they were going to do next. That is why I ended up watching it. I don't know why they don't show it more often. I would rather watch this than some films they play more than necessary. For history buffs, people who like period films, and those that are in the film appreciation groups will like this one. \\\"The Egyptian\\\" has a variety of flavors dealing with a lot of things to look at in human nature that has not changed since it's time. What does that say about us? Those that don't like movies that take their time to unfold and tell a good story....are not into film.<br /><br />I haven't had the time to rent it if it is available, but if I get a chance to see it again, I would probably vote it a 10.\",\n          \"More of a near miss than a flop, MR. IMPERIUM stars Ezio Pinza as Alex, heir apparent to and later king of a small European nation, who falls in love with a willing American actress and entertainer, Fredda Barlo (Lana Turner), but due to machinations by the sly prime minister of Alex as king, nicely played by Cedric Hardwicke, the lovers are separated for 12 years before being reunited in Palm Springs where their love is rekindled. Director Don Hartman, who also scripts, is not able to fully utilize his talent for snappy dialogue because of Pinza's tentative English usage, and the requisite rewriting, coupled with less than total rapport in evidence between the two stars, results in a somewhat raggedy tone to the screenplay, exacerbated by the studio's unkind cutting of many scenes, leading to a confusing ending. The overpowering Pinza dominates his scenes with Turner, but both performers score with good work, while Marjorie Main is impressive with her patter effects as written, with Debbie Reynolds placed on track by Louis B. Mayer for SINGIN' IN THE RAIN as a result of her sprightly performance here; only Barry Sullivan is heavily victimized by the flagrant cutting. Prettily filmed largely in Pebble Beach, California, and other Monterey County environs, the film is endowed with Pinza's iron strong operatic basso in Solamente Una Vez, as well as with original songs by Harold Arlen and Dorothy Fields, with Douglas Shearer splendidly handling the sound recording, and notice must be made of the fine set decorations by Edwin Willis, and the effective costume designs by Walter Plunkett.\",\n          \"One of the best western movies ever made. Unfortunately, it never got the recognition it deserved. The storyline, the action and the music was in my mind, one of the best. I give it a double A+. Randolph Scott gave a terrific performance along with the other members of the cast. The ending was one of the best of any western made.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review = df[df['sentiment']=='positive']\n",
        "negative_review = df[df['sentiment']=='negative']"
      ],
      "metadata": {
        "id": "b7Zj25mx4UoR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_review.iloc[0]['review']"
      ],
      "metadata": {
        "id": "tmh1Oep35JLb",
        "outputId": "f2122593-7581-4b18-fb28-515cb319304e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_review.iloc[0]['review']"
      ],
      "metadata": {
        "id": "3erDLibm5NZ7",
        "outputId": "d69118b3-3ce6-4bbd-82d5-c860413a0b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The film quickly gets to a major chase scene with ever increasing destruction. The first really bad thing is the guy hijacking Steven Seagal would have been beaten to pulp by Seagal's driving, but that probably would have ended the whole premise for the movie.<br /><br />It seems like they decided to make all kinds of changes in the movie plot, so just plan to enjoy the action, and do not expect a coherent plot. Turn any sense of logic you may have, it will reduce your chance of getting a headache.<br /><br />I does give me some hope that Steven Seagal is trying to move back towards the type of characters he portrayed in his more popular movies.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "Positive Review:\n",
        "The positive review is detailed and covers multiple aspects of the event, but it also contains criticisms, such as calling the main event \"terrible.\"\n",
        "This mixed sentiment can be challenging for sentiment analysis models, as they may struggle to classify the review correctly.\n",
        "The review includes subjective phrases and domain-specific references to wrestling, which require contextual understanding.\n",
        "\n",
        "Negative Review:\n",
        "The negative review highlights issues with the movie's plot and logic, but it also includes a small positive remark as well.\n",
        "Since the review lacks an explicit sentiment score, it may require additional processing to quantify its negativity accurately.\n",
        "Handling sarcasm, fixing formatting issues, and addressing mixed sentiment are key challenges in analyzing such data.\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "fcIjeLLk0sE2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (ii) [1pt EXPLORATORY]\n",
        "\n",
        "Perform summary statistics on the dataset. What is the average character length of a review? What are the lengths of the longest and shortest reviews?\n",
        "\n",
        "How many positive reviews and negative reviews are there. Generate a histogram to compare the average character length for positive and negative reviews. Comment on the differences in positive and negative reviews and how that may affect the model you will be using later."
      ],
      "metadata": {
        "id": "QaDPP2Ei5k8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "df['review_length'] = df['review'].str.len()\n",
        "average_length = df['review_length'].mean()\n",
        "longest_review = df['review_length'].max()\n",
        "shortest_review = df['review_length'].min()\n",
        "positive_reviews = df[df['sentiment'] == 'positive']\n",
        "negative_reviews = df[df['sentiment'] == 'negative']\n",
        "positive_length = positive_reviews['review_length'].mean()\n",
        "negative_length = negative_reviews['review_length'].mean()\n",
        "num_positive = len(positive_reviews)\n",
        "num_negative = len(negative_reviews)\n",
        "\n",
        "print(f\"Average review length: {average_length:.2f}\")\n",
        "print(f\"Longest review length: {longest_review}\")\n",
        "print(f\"Shortest review length: {shortest_review}\")\n",
        "print(f\"Average length of positive reviews: {positive_length:.2f}\")\n",
        "print(f\"Average length of negative reviews: {negative_length:.2f}\")\n",
        "print(f\"Number of positive reviews: {num_positive}\")\n",
        "print(f\"Number of negative reviews: {num_negative}\")\n",
        "\n",
        "# Histogram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(positive_reviews['review_length'], bins=50, alpha=0.5, label=\"Positive Reviews\")\n",
        "plt.hist(negative_reviews['review_length'], bins=50, alpha=0.5, label=\"Negative Reviews\")\n",
        "plt.xlabel(\"Review Length (Characters)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Review Lengths\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Y_7EmD9-Fly",
        "outputId": "20d02dfb-b7d1-4420-9b0c-5a0293e3844a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average review length: 1311.24\n",
            "Longest review length: 13704\n",
            "Shortest review length: 32\n",
            "Average length of positive reviews: 1325.87\n",
            "Average length of negative reviews: 1296.60\n",
            "Number of positive reviews: 20004\n",
            "Number of negative reviews: 19996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "General observations:\n",
        "The histogram shows that the majority of reviews length fall within a relatively short to moderate range, with a right-skewed tail extending to much longer reviews.\n",
        "The average review length is 1,311 characters, indicating that most reviews provide at least a few paragraphs of detail. Nonetheless, there are outliers on the high end, with the longest review being 13,704 characters suggesting some users write extremely detailed reviews.\n",
        "The shortest review in the dataset is just 32 characters, reflecting that some users provide very concise feedback. Such short reviews may lack rich sentiment cues and could pose challenges for text classification models.\n",
        "\n",
        "Observations positive vs negative:\n",
        "Positive reviews tend to be slightly longer on average (1,325.87) compared to negative reviews (1,296.60).\n",
        "While this difference is not large, it suggests that people who are satisfied with a product or experience may provide more detail.\n",
        "Both positive and negative reviews follow a similar distribution shape, indicating that the review length alone may not be a strong distinguishing factor between sentiment categories.\n",
        "When building text classification models, it will be important to address any potential length-based bias by either normalizing input size or leveraging advanced architectures (such as transformers) that can effectively handle variable-length text without overreliance on mere character count.\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "gPSFCNYI6F4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (iii) [1pt EXPLORATORY]\n",
        "\n",
        "The following helper code will be used to process the data before we can train our LSTM model. In point form comment on what processing steps are performed in the code provided below and why these steps are necessary or beneficial to training and LSTM."
      ],
      "metadata": {
        "id": "ShOy3jp2zpRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "6aamEcrqCqtU",
        "outputId": "cfab7352-72c4-46e1-f333-3d8d4aa554c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_string(str1):\n",
        "    # remove all non-word characters excluding number and letters\n",
        "    str1= re.sub(r\"[^\\w\\s]\",'',str1)\n",
        "    # remove all whitespace with no space\n",
        "    str1= re.sub(r\"\\s\",'',str1)\n",
        "    # replace digits with no space\n",
        "    str1= re.sub(r\"\\d\",'',str1)\n",
        "    return str1\n",
        "\n",
        "def preprocess_sentence(sen1):\n",
        "    word_list=[]\n",
        "    stop_word = set(stopwords.words(\"english\"))\n",
        "    for word in sen1.lower().split():\n",
        "        word = preprocess_string(word)\n",
        "        if word not in stop_word and word!='':\n",
        "            word_list.append(word)\n",
        "    return word_list\n",
        "\n",
        "def get_stoi(data):\n",
        "    word_list=[]\n",
        "    for review in data:\n",
        "        word_list.extend(preprocess_sentence(review))\n",
        "    corpus = Counter(word_list)\n",
        "    print(corpus.get)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ =sorted(corpus,key= corpus.get,reverse=True)[:1000]\n",
        "    # creating a dict\n",
        "    stoi =  {ch:i+1 for i,ch in enumerate(corpus_)}\n",
        "    return stoi\n",
        "\n",
        "def tokenize(data, labels, stoi):\n",
        "    # tokenize\n",
        "    data_encoded = []\n",
        "    for review in data:\n",
        "        data_encoded.append([stoi[word] for word in preprocess_sentence(review)\n",
        "                             if word in stoi.keys()])\n",
        "\n",
        "    labels_encoded = [1 if label =='positive' else 0 for label in labels]\n",
        "\n",
        "    return np.array(data_encoded, dtype=object), np.array(labels_encoded)\n",
        "\n",
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review)!=0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "tAjcY6oPz61e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "CHDGI2rn12G_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie_D0bv9a90k"
      },
      "source": [
        "### Part (iv) [1pt EXPLORATORY]\n",
        "\n",
        "Split the dataset into `train`, `valid`, and `test`. Use a 60-20-20 split. Then apply the above processing steps to prepare your data for training.\n",
        "\n",
        "Set the padding of the reviews to 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Y6Puz9a90l"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff5CNk7Qa90y"
      },
      "source": [
        "### Part (v) [1pt EXPLORATORY]\n",
        "\n",
        "Create a DataLoader that will allow you to load the training and validation data in mini-batches. Then generate a dataset of batch size of 16 to verify that the DataLoader works as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8N8qLWOa90y"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HnqP6_a904"
      },
      "source": [
        "## Part 2. Model Building [2pt MODEL]\n",
        "\n",
        "Build a recurrent neural network model, using an architecture of your choosing. Use one or more fully-connected layers to make the prediction based on your recurrent network output.\n",
        "\n",
        "An example is provided below in `BaselineSentimentRNN`, which you can use for inspiration. However, you should build your own model.\n",
        "\n",
        "Instead of using the RNN output value for the final token, another often used strategy is to max-pool over the entire output array. That is, instead of calling something like:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(out[:, -1, :])\n",
        "```\n",
        "\n",
        "where `self.rnn` is an `nn.RNN`, `nn.GRU`, or `nn.LSTM` module, and `self.fc` is a\n",
        "fully-connected\n",
        "layer, we use:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "self.fc(torch.max(out, dim=1)[0])\n",
        "```\n",
        "\n",
        "This works reasonably in practice. An even better alternative is to concatenate the max-pooling and average-pooling of the RNN outputs:\n",
        "\n",
        "```\n",
        "out, _ = self.rnn(x)\n",
        "out = torch.cat([torch.max(out, dim=1)[0],\n",
        "                 torch.mean(out, dim=1)], dim=1)\n",
        "self.fc(out)\n",
        "```\n",
        "\n",
        "We encourage you to try out all these options. The way you pool the RNN outputs is one of the \"hyperparameters\" that you can choose to tune later on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineSentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=4, hidden_dim=4, output_dim=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        # Vanilla RNN returns: outputs, hidden\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # hidden.shape = (num_layers, batch_size, hidden_dim)\n",
        "        out = self.fc(hidden[-1])  # take the last layer's hidden state\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "WhlW4QG-38Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LTQ7zFka909"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        # TO BE COMPLETED\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        # TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n",
        "model = SentimentRNN()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIYPl_Ba90_"
      },
      "source": [
        "## Part 3. Training [3 pt]\n",
        "\n",
        "### Part (i) [1pt MODEL]\n",
        "\n",
        "Complete the `get_accuracy` function, which will compute the\n",
        "accuracy (rate) of your model across a dataset (e.g. validation set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvNfhGD6a91A"
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "    >>> model = MyRNN() # to be defined\n",
        "    >>> get_accuracy(model, valid_loader) # the variable `valid_loader` is from above\n",
        "    \"\"\"\n",
        "\n",
        "    # TO BE COMPLETED\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlxlcAC1a91C"
      },
      "source": [
        "### Part (ii) [1pt MODEL]\n",
        "\n",
        "Train your model. Plot the training curve of your final model.\n",
        "Your training curve should have the training/validation loss and\n",
        "accuracy plotted periodically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVtf7CJCa91D"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE3eRkDAa91F"
      },
      "source": [
        "### Part (iii) [1pt MODEL]\n",
        "\n",
        "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters.\n",
        "You don't need to include your training curve for every model you trained.\n",
        "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
        "and the reasoning behind the hyperparameter decisions you made.\n",
        "\n",
        "For this assignment, you should tune more than just your learning rate and epoch.\n",
        "Choose at least 2 hyperparameters that are unrelated to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2GEWfDca91G"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "mN2t6fSzryME"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gznefulsa91V"
      },
      "source": [
        "## Part 4. Evaluation [10 pt]\n",
        "\n",
        "**Important**. At this point in the assignment your test data should not have been evaluated by any of your models. The test data should be evaluated only after you have finished all the previous parts of the assignment. Once you evaluate your models on the test data you cannot change your models or else you may make hyperparameter adjustments that could lead to overfitting to the test data.\n",
        "\n",
        "### Part (i) [3pt RESULT]\n",
        "\n",
        "Report the final test accuracy of your model. Comment on how the result compares with accuracy obtained on the training and validation data. Are the results what you expected? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5L5D-A1a91W"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "DTHWBJCu_Fyz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLvxrCP5Bwdu"
      },
      "source": [
        "### Part (ii) [3pt DISCUSSION]\n",
        "\n",
        "Look over the misclassified samples in the test data and see if you can find any patterns on where the model has difficulty with identifying the review sentiment. Provide up to 5 examples of positive and negative reviews each to support your findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJt0APcBBwd5"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Fyr16MISBwd5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jGHtQFpa91b"
      },
      "source": [
        "### Part (iii) [2pt RESULT]\n",
        "\n",
        "What is your model's prediction of the **probability** that\n",
        "the review message provided below is a positive review?\n",
        "\n",
        "Hint: You will need to apply the same processing on the review as was done on the the train, val, and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2nSJq8a91b"
      },
      "source": [
        "review = \"\"\" Man.... I wish I loved this movie more than I did. Don't get me wrong,\n",
        "it's a solid action movie with jaw-dropping stunts (some of the best in the series),\n",
        "but as a Mission: Impossible movie, it felt like a small step backward for the franchise.\n",
        "Fallout had mind-blowing action sequences and stunt work, along with developing Ethan's\n",
        "relationship with Ilsa, providing closure with Julia, showing the lengths Ethan would\n",
        "go to protect those closest to him, and battling an imposing villain. Dead Reckoning:\n",
        "Part One stretches the movie across two films only to seemingly showcase action\n",
        "spectacle after action spectacle while sacrificing character development.\n",
        "Characters I have grown to love over a decade of films felt sidelined, ignored,\n",
        "or wasted. Hayley Atwell's new character chewed up most of the screen time, and\n",
        "while she was fantastic, I wanted to see more of the original team. The new villain\n",
        "had an inconsistent ability that confused more than intimidated. There were some\n",
        "important emotional moments that I just didn't feel the weight of when I definitely\n",
        "should have. Part Two might tie everything together and make me enjoy Part One\n",
        "more in retrospect, but unfortunately, I left wanting more from this one. \"\"\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CB-82EtwBmKb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1zgYJpa91f"
      },
      "source": [
        "### Part (iv) [2pt DISCUSSION]\n",
        "\n",
        "Do you think that detecting positive and negative reviews is an easy or difficult task?\n",
        "\n",
        "Since machine learning models are expensive to train and deploy, it is very\n",
        "important to compare our models against baseline models: a simple\n",
        "model that is easy to build and inexpensive to run that we can compare our\n",
        "recurrent neural network model against.\n",
        "\n",
        "Explain how you might build a simple baseline model. This baseline model\n",
        "can be a simple neural network (with very few weights), a hand-written algorithm,\n",
        "or any other strategy that is easy to build and test.\n",
        "\n",
        "**Do not actually build a baseline model. Instead, provide instructions on\n",
        "how to build it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dwiiZYdvz34"
      },
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIR3Q5l0v1HP"
      },
      "source": [
        "# PART B - Transfer Learning\n",
        "\n",
        "For many natural language processing tasks, it is generally not a good idea to train a very large deep neural network model from scratch due to enormous compute requirements and lack of sufficient amounts of training data. Instead, you should always try to take advantage of an existing model that performs similar tasks as the one you need to solve.\n",
        "\n",
        "In this part of the assignment we will be using pretrained models to improve the performance on identifying positive and negative reviews. There are several pretrained models that are available to us, here we will use a pretrained BERT model that comes with the hugging face transformer library.\n",
        "\n",
        "Provided below is sample code to get you started. For more details please visit the hugging face tutorial on using pretrained models using PyTorch: https://huggingface.co/docs/transformers/training\n",
        "\n",
        "#### Sample Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R-_BQyiAMoo"
      },
      "source": [
        "# install relevant libraries\n",
        "!pip install -qq transformers"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "316Xs5WBv0kg"
      },
      "source": [
        "# load relevant libraries\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "################### SUBMISSION NOTE ####################################\n",
        "#  - output of this cell creates issues for converting ipynb to HTML\n",
        "#  - you may want to delete this output when you are ready to submit"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sample_txt = 'I want to learn how to do sentiment analysis using BERT and tokenizer.'\n",
        "\n",
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        "  truncation = True\n",
        ")"
      ],
      "metadata": {
        "id": "_20pdf-tYySb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoding['input_ids']"
      ],
      "metadata": {
        "id": "O1B4RiOOcbGY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoding['attention_mask']"
      ],
      "metadata": {
        "id": "7sZ1j9PfceFF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states = bert_model(input_ids=encoding['input_ids'],\n",
        "                           attention_mask=encoding['attention_mask'])[0]\n",
        "pooled_output = bert_model(input_ids=encoding['input_ids'],\n",
        "                           attention_mask=encoding['attention_mask'])[1]"
      ],
      "metadata": {
        "id": "dZ458Q_uYzxu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = bert_model.config.hidden_size\n",
        "\n",
        "print(hidden_size)\n",
        "print(hidden_states.shape)\n",
        "print(pooled_output.shape)\n"
      ],
      "metadata": {
        "id": "GqwUAEIzZNBO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the sample code provided we loaded a short text sequence, tokenized it using the same tokenization that was used in the pretrained BERT model, and fed the tokenized input into the BERT model to obtain the embeddings.\n",
        "\n",
        "The model output consists of two forms of embeddings:\n",
        "- **hidden_states** are the final layer of outputs that has a shape sequence_length x embeddings, much like the hidden states of a recurrent neural network\n",
        "- **pooled_output** is the result of applying max pooling on the hidden states to effectively collapse the sequence dimenension and ensure the same output size for any given sequence before feeding into the classification stage\n",
        "\n",
        "Note that we preprocess all of the data prior to training a classifier stage for sentiment analysis to help speed up the training process. This is no different from the process we applied in an earlier assignment using AlexNet and image data."
      ],
      "metadata": {
        "id": "7HCaqLDaZo2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Data Loading [5 pt]\n",
        "\n",
        "We will be using the same \"IMDB Movie Review Dataset\" that we used earlier. Reload the data and complete Part B of the assignment. You should be able to complete part B independently from Part A.\n",
        "\n",
        "### Part (i) [1pt EXPLORATORY]\n",
        "\n",
        "Provided below is a DataLoader for your training and test datasets so you can iterate over batches of data. Run the DataLoader to create your training, validation, and test data."
      ],
      "metadata": {
        "id": "4le9bqnuc2JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MovieReviewDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        reviews,\n",
        "        targets,\n",
        "        tokenizer,\n",
        "        max_len,\n",
        "        bert_model=None,\n",
        "        embed_folder='embeddings',\n",
        "        precompute=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        reviews     : array/list of text data\n",
        "        targets     : array/list of 'positive'/'negative' labels\n",
        "        tokenizer   : BERT tokenizer\n",
        "        max_len     : maximum sequence length for tokenization\n",
        "        bert_model  : a BERT model for generating embeddings (if precompute=True)\n",
        "        embed_folder: folder to store .pt files of precomputed embeddings\n",
        "        precompute  : True -> generate & save embeddings, False -> load from disk only\n",
        "        \"\"\"\n",
        "        self.reviews = reviews\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.bert_model = bert_model\n",
        "        self.embed_folder = embed_folder\n",
        "        self.precompute = precompute\n",
        "\n",
        "        # Create the folder if it doesn't exist\n",
        "        if not os.path.exists(self.embed_folder):\n",
        "            os.makedirs(self.embed_folder)\n",
        "\n",
        "        if self.precompute and (self.bert_model is not None):\n",
        "            self._precompute_embeddings()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a dictionary with:\n",
        "          - 'review_text'   : original text (optional, for reference)\n",
        "          - 'pooled_output' : [768]-dim embedding from BERT\n",
        "          - 'last_hidden'   : [seq_len, 768] from the last hidden layer\n",
        "          - 'targets'       : 0 or 1\n",
        "        \"\"\"\n",
        "        review = str(self.reviews[idx])\n",
        "        target = 1 if self.targets[idx] == 'positive' else 0\n",
        "\n",
        "        embed_path = os.path.join(self.embed_folder, f'embedding_{idx}.pt')\n",
        "        # Load precomputed embeddings\n",
        "        embedding_dict = torch.load(embed_path)\n",
        "\n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'pooled_output': embedding_dict['pooled'],\n",
        "            'last_hidden': embedding_dict['last'],\n",
        "            'targets': torch.tensor(target, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "    def _precompute_embeddings(self, batch_size=256, device=\"cuda\"):\n",
        "        \"\"\"\n",
        "        Precompute embeddings in batches rather than one by one.\n",
        "        \"\"\"\n",
        "        # Move the model to device (CPU/GPU)\n",
        "        self.bert_model = self.bert_model.to(device)\n",
        "        self.bert_model.eval()\n",
        "\n",
        "        print(\"Precomputing BERT embeddings (batched)...\")\n",
        "\n",
        "        # 1) Tokenize everything\n",
        "        encodings = [self.tokenizer.encode_plus(\n",
        "            str(review),\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        ) for review in self.reviews]\n",
        "        input_ids = torch.cat([e['input_ids'] for e in encodings], dim=0)\n",
        "        attention_masks = torch.cat([e['attention_mask'] for e in encodings], dim=0)\n",
        "\n",
        "        # 2) Create a TensorDataset and DataLoader\n",
        "        dataset_tensors = TensorDataset(input_ids, attention_masks)\n",
        "        dataloader = DataLoader(dataset_tensors, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # We'll need to index back into `self.reviews` to save each sample‚Äôs .pt\n",
        "        idx_offset = 0\n",
        "\n",
        "        for batch in tqdm(dataloader, total=len(dataloader)):\n",
        "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.bert_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    output_hidden_states=True\n",
        "                )\n",
        "            # outputs.pooler_output.shape is [batch_size, hidden_dim]\n",
        "            # outputs.hidden_states[-1].shape is [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "            pooled_output_batch = outputs.pooler_output.detach().cpu()\n",
        "            last_hidden_batch = outputs.hidden_states[-1].detach().cpu()\n",
        "\n",
        "            # 3) Save each sample in the batch\n",
        "            for i in range(len(input_ids)):\n",
        "                sample_idx = idx_offset + i\n",
        "                embed_path = os.path.join(self.embed_folder, f'embedding_{sample_idx}.pt')\n",
        "\n",
        "                # Skip if already exists (optional check)\n",
        "                if os.path.isfile(embed_path):\n",
        "                    continue\n",
        "\n",
        "                embedding_dict = {\n",
        "                    'pooled': pooled_output_batch[i].detach().cpu().clone(),\n",
        "                    'last': last_hidden_batch[i].detach().cpu().clone()\n",
        "                }\n",
        "\n",
        "                torch.save(embedding_dict, embed_path)\n",
        "\n",
        "            idx_offset += len(input_ids)\n",
        "\n",
        "        print(\"Done precomputing embeddings.\")\n"
      ],
      "metadata": {
        "id": "LzlpaXmteHQd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data loaders\n",
        "MAX_LEN = 400\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "#training data\n",
        "train_dataset = MovieReviewDataset(\n",
        "    reviews=df_train['review'].values,\n",
        "    targets=df_train['sentiment'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN,\n",
        "    bert_model=bert_model,       # required if we want to precompute now\n",
        "    embed_folder='train_embeds', # folder to save embeddings\n",
        "    precompute=True              # set to True so we generate them\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=4\n",
        ") #modify num_works as needed\n",
        "\n",
        "\n",
        "#validation data\n",
        "\n",
        "# TO BE COMPLETED\n",
        "\n",
        "#test data\n",
        "\n",
        "# TO BE COMPLETED\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "27_5roCZeI8T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (ii) [1pt EXPLORATORY]\n",
        "\n",
        "Use the **train_data_loader** to load one sample. What are the different attributes provided with the sample and how are they used?"
      ],
      "metadata": {
        "id": "g0ymyMvzfdVv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HVP_C6JnU2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UgdwGNtik1ZR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "OOVKM8kPdPwC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (iii) [1pt EXPLORATORY]\n",
        "\n",
        "Determine the range of values for the tokens in the training data. How are the tokens obtained?\n",
        "\n",
        "Hint: You can apply your intuition here, or do some additional research to find how the \"bert-base-cased\" tokenization is done."
      ],
      "metadata": {
        "id": "GXQt2HiGfh4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6cVEH5YhkYUQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Im2KNoOPdYHU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (iv) [1pt EXPLORATORY]\n",
        "\n",
        "Generate histograms of all the token values in the training data. Repeat for the validation and test data. What are the top 5 occuring tokens in the training_dataset? What do these tokens represent?"
      ],
      "metadata": {
        "id": "6CYKglzbfTmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HTZdkR7ukhRg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "fS1c0a6wddHl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (v) [1pt EXPLORATORY]\n",
        "\n",
        "Select a single sample from your training DataLoader and feed it through the **bert_model** to obtain the hidden_states and pooled_output. Briefly describe what each tensor dimension represents and what affects the size of each dimension."
      ],
      "metadata": {
        "id": "3ElnJDdgcaiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1HOknY9Ncai9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "34OnAb9EdjtW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Model Architecture [2 pt]\n",
        "\n",
        "### Part (i) [1pt MODEL]\n",
        "\n",
        "Prepare a review classifier model that builds on the pooled output from the Bert model to identify positive and negative reviews.\n",
        "\n",
        "\n",
        "An example is provided below in `BaselineSentimentClassifierPooled`, which you can use for inspiration. However, you should build your own model."
      ],
      "metadata": {
        "id": "rDbQ7nRBek5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineSentimentClassifierPooled(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BaselineSentimentClassifierPooled, self).__init__()\n",
        "        self.linear = nn.Linear(768, n_classes)\n",
        "\n",
        "    def forward(self, pooled_embedding):\n",
        "        \"\"\"\n",
        "        pooled_embedding: shape [batch_size, 768]\n",
        "        \"\"\"\n",
        "        outputs = self.linear(pooled_embedding)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "gNDd-010GSnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierPooled(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifierPooled, self).__init__()\n",
        "    # We don't need BERT here, since we have precomputed embeddings\n",
        "    # TO BE COMPLETED\n",
        "\n",
        "  def forward(self, pooled_embedding):\n",
        "    # TO BE COMPLETED\n",
        "\n"
      ],
      "metadata": {
        "id": "kAISbN5VexqS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (ii) [1pt MODEL]\n",
        "\n",
        "Construct the architecture for a review classifier model that uses the last hidden output from the Bert model to identify positive and negative reviews.\n",
        "\n",
        "An example is provided below in `BaselineSentimentClassifierLast`, which you can use for inspiration . However, you should build your own model.\n"
      ],
      "metadata": {
        "id": "RLFzooLUgn3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineSentimentClassifierLast(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BaselineSentimentClassifierLast, self).__init__()\n",
        "        # Again, no BERT directly needed if using precomputed data\n",
        "        self.linear = nn.Linear(768, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, last_hidden):\n",
        "        \"\"\"\n",
        "        last_hidden: shape [batch_size, seq_len, 768]\n",
        "        We'll do a simple max-pool across seq_len dimension => shape [batch_size, 768]\n",
        "        \"\"\"\n",
        "        # last_hidden has shape [B, T, 768]\n",
        "        # we want max across T => shape [B, 768]\n",
        "        x, _ = torch.max(last_hidden, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        outputs = self.linear(x)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "pqDKQse6H-Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifierLast(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifierLast, self).__init__()\n",
        "    # We don't need BERT here, since we have precomputed embeddings\n",
        "    # TO BE COMPLETED\n",
        "\n",
        "  def forward(self, last_hidden):\n",
        "\n",
        "    # TO BE COMPLETED\n"
      ],
      "metadata": {
        "id": "Q34oWGhoe38H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqkKp1CgiYZb"
      },
      "source": [
        "## Part 3. Training [3 pt]\n",
        "\n",
        "### Part (i) [1pt MODEL]\n",
        "\n",
        "Complete the `get_accuracy` function, which will compute the\n",
        "accuracy (rate) of your model across a dataset (e.g. validation set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC89f2i7iYZl"
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "    >>> model = MyRNN() # to be defined\n",
        "    >>> get_accuracy(model, valid_loader) # the variable `valid_loader` is from above\n",
        "    \"\"\"\n",
        "\n",
        "    # TO BE COMPLETED\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruaRg5JCiYZm"
      },
      "source": [
        "### Part (ii) [1pt MODEL]\n",
        "\n",
        "Write a function **train_model** to train your model. Plot the training curve of your final model.\n",
        "Your training curve should have the training/validation loss and\n",
        "accuracy plotted periodically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuqypAPxiYZm"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVvzpQRWiYZm"
      },
      "source": [
        "### Part (iii) [1pt MODEL]\n",
        "\n",
        "Choose at least 4 hyperparameters to tune. Explain how you tuned the hyperparameters. You don't need to include your training curve for every model you trained.\n",
        "Instead, explain what hyperparemters you tuned, what the best validation accuracy was,\n",
        "and the reasoning behind the hyperparameter decisions you made.\n",
        "\n",
        "For this assignment, you should tune more than just your learning rate and epoch.\n",
        "Choose at least 2 hyperparameters that are unrelated to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCZtA9iiYZm"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "N9o-7udJmahe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4. Evaluation [10 pt]\n",
        "\n",
        "### Part (i) [3pt RESULT]\n",
        "\n",
        "Report the final test accuracy of your best BERT-based model. Then summarize in a pandas dataframe the accuracy obtained on the training, validation, and test data of your best models from Part A and B.\n",
        "\n",
        "How does the BERT model compare to the approach in part A using only LSTM? Are the results what you expected? Explain.\n",
        "\n"
      ],
      "metadata": {
        "id": "ecKaJIpQe9UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AoweZb8i2cRb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "1RIZ3JWzm2a_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybdyEKx5Ww4F"
      },
      "source": [
        "### Part (ii) [2pt RESULT]\n",
        "\n",
        "Report the false positive rate and false negative rate of your model across the test set. Then summarize in a pandas dataframe the false postive and false negative rate of your model obtained on the training, validation, and test data of your best models from Part A and B.\n",
        "\n",
        "How does the BERT model compare to the approach in part A using only LSTM? Are the results what you expected? Explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuxLCHhFWw4F"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "vIu8lB9jm3X_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "646WjsAwWw4F"
      },
      "source": [
        "### Part (iii) [3pt DISCUSSION]\n",
        "Examine some of the misclassified reviews from you best BERT and LSTM models to better identify the differences in the models. Try to provide some justification for any differences in the misclassifications observed in the models.\n",
        "\n",
        "Is there any part of the review that you could modify to make the classifications correct? Try to make small changes to the review to see if you can make the model make the correct classification while keeping the review as close to the original as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OvvnW8OWw4G"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "7TWkK5Sgm4YM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4FlSj_Mn2yY"
      },
      "source": [
        "### Part (iv) [2pt DISCUSSION]\n",
        "Find 5 samples of positive and negative reviews on IMDB that were posted recently and evaluate them with your best BERT and LSTM models from parts A and B. How well do they perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3DCyMW_n05f"
      },
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "0kLt9a5Xm5cO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART C (Optional) - Bonus Challenge!\n",
        "\n",
        "This is an optional exercise for those that finish the assignment early and would like to take on a challenging task.\n",
        "\n",
        "In part A we constructed and trained an LSTM model to identify the sentiment in movie reviews. In Part B we used the embeddings of a BERT model pretrained on a large corpus of text to demonstrate how transfer learning can be used to improve our movie sentiment model. The BERT model is one of many language models that we could have used to implement transfer learning.\n",
        "\n",
        "For this bonus challenge you are asked to implement a generative character-level LSTM model to produce IMDB movie reviews. Once the model is sufficiently trained you can then use its hidden states as the embedding for training a movie sentiment model. Construct your new movie sentiment analysis model and compare the performance against the model from part A and B.\n",
        "\n",
        "There are many variants of a generative LSTM model that you can consider. As a starting point you can use the generative LSTM sample code provided in the lecture notes. Specifically, the one used to generate Shakeaspeare. More advanced versions of a generative LSTM can be found in the Universal Language Model Fine-turing for Text Classification (ULMfit) paper (https://arxiv.org/abs/1801.06146).\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Create a generative character-level LSTM model trained to create IMDB reviews\n",
        "2. Create a classifier using the embeddings from the generative LSTM model (from step 1) to identify positive and negative reviews.\n",
        "3. Compare the performance of the model with the results in parts A and B of the assignment.\n",
        "4. Upgrade the generative LSTM model using the techniques listed in the ULMfit paper (e.g., bi-directional LSTM, pretraining with wikipedia text and fine-tuning on IMDBT reviews, etc.).\n",
        "\n",
        "Bonus marks will be provided based on the number of steps completed. Summarize below your results and anything intersting you learned from the steps that you completed. Bonus marks cannot be accumulated beyond a maximum assignment grade.\n"
      ],
      "metadata": {
        "id": "ARDyU7N2mWFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE COMPLETED\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9eUKPfCumdpW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PROVIDE YOUR ANSWER BELOW\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ryS5uR0NB8pE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYwI4RmFS2RB"
      },
      "source": [
        "### Saving to HTML\n",
        "Detailed instructions for saving to HTML can be found <a href=\"https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab/64487858#64487858\">here</a>. Provided below are a summary of the instructions:\n",
        "\n",
        "(1) download your ipynb file by clicking on File->Download.ipynb\n",
        "\n",
        "(2) reupload your file to the temporary Google Colab storage (you can access the temporary storage from the tab to the left)\n",
        "\n",
        "(3) run the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TrsqdNgS5ex"
      },
      "source": [
        "# #!pip install nbconvert\n",
        "\n",
        "# %%shell\n",
        "# jupyter nbconvert --to html /content/A4.ipynb\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuXhlFlPTY7F"
      },
      "source": [
        "(4) the html file will be available for download in the temporary Google Colab storage\n",
        "\n",
        "(5) review the html file and make sure all the results are visible before submitting your assignment to Quercus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Grading Rubric\n",
        "The grading of the assignment will be based on the following categories:\n",
        "\n",
        "(1) **10 Pt - EXPLORATORY QUESTIONS** These are basic questions that in most cases can be answered without requiring a fully working and trained neural network model. For example, data loading, processing and visualization, summary statistics, data exploration, model and training setup, etc.\n",
        "\n",
        "(2) **10 Pt - MODEL** Student has successfully implemented all the required neural network models and has demonstrated successful training of the model without any errors.\n",
        "\n",
        "(3) **10 Pt - RESULT** Students are evaluated based on the results achieved in comparison to the expected results of the assignment.\n",
        "\n",
        "(4) **10 Pt - DISCUSSION QUESTIONS** Student demonstrated understanding beyond the basic exploratory questions, can answer some of the more challenging questions, and provide arguments for their model selection decisions.\n",
        "\n",
        "(5) **10 Pt - COMMUNICATION** Student has provided a quality submission that is easy to read without too many unnecessary output statements that distract the reading of the document. The code has been well commented and all the answers are communicated clearly and concisely.\n",
        "\n",
        "(6) **10 Pt - BONUS** Student has completed the assignment and has taken on the challenging bonus tasks listed in PART C. The student has demonstrated a good understanding of all aspects of the assignment and has exceeded expectations for the assignment.\n",
        "\n",
        "\n",
        "\n",
        "**TOTAL GRADE = _____ of 50 Pts**"
      ],
      "metadata": {
        "id": "Oo8xLbm4mggI"
      }
    }
  ]
}